{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "17f9ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "533237aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e1275a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Karthiek\n",
      "[nltk_data]     Duggirala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5716ff32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Karthiek\n",
      "[nltk_data]     Duggirala\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "451b897c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self,data):\n",
    "        self.stoplist = stopwords.words('english')\n",
    "        preset_steplist_upper =  [token.capitalize() for token in stopwords.words('english')]\n",
    "        self.stoplist.extend(preset_steplist_upper)\n",
    "        additional_stoplist = ['.', '!', '\\'s', '?', ';', 'n\\'t', '\\'ll', 'would', '--', 'ta', 'wan', 'ai',\n",
    "                               'na', 'ya', 'could', 'It', 'am', '\\'m', ',', '\\'', '\\'re', 'u', '``', '\\'\\'',\n",
    "                               'wa', 'ca', '\\'em', '...', ':', 'em', 'wit', 'wo', 'ya', 'gon', 'y\\'all', \n",
    "                               '\\'ve', 'im', '\\'cause', 'cause', '\\'d', '-' 'ha', 'un']\n",
    "        self.stoplist.extend(additional_stoplist)\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        \n",
    "    def preprocess(self, dataset):\n",
    "        songs = []\n",
    "        for index, row in dataset.iterrows():\n",
    "            genre = row['genre']\n",
    "            lyrics = self.clean_text(row['lyrics'])\n",
    "            tokens = nltk.word_tokenize(lyrics)\n",
    "            clean_tokens = [self.word_cleanup(token) for token in tokens if self.word_cleanup(token) is not None]\n",
    "            if len(clean_tokens) > 0:\n",
    "                new_text = \" \".join(clean_tokens)\n",
    "                songs.append([new_text, genre])\n",
    "        return pd.DataFrame(songs, columns=['lyrics', 'genre'])\n",
    "    \n",
    "    def clean_text(self, text):\n",
    "        text = re.sub(r'\\[.*\\]|\\(.*\\)|\\{.*\\}', '', text)\n",
    "        text = text.lower()\n",
    "        text = re.sub('\\w*\\d\\w*', '', text)\n",
    "        text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "        text = re.sub('\\n', ' ', text)\n",
    "        text = re.sub(' +', ' ', text)\n",
    "        text = text.strip()\n",
    "        return text\n",
    "    \n",
    "    def word_cleanup(self, word):\n",
    "        if re.match(r'[Nn]ig[agsz]{1,3}', word):\n",
    "            return 'n-word'\n",
    "        if re.match(r'[Oo]{1}h*', word):\n",
    "            return None\n",
    "        if re.match(r'[Ll]?[Aa]{1}', word):\n",
    "            return None\n",
    "        nums = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "        words = ['zero','one','two','three','four','five','six','seven','eight','nine']\n",
    "        if word in nums:\n",
    "            return words[int(word)]\n",
    "        new_word =  self.lemmatizer.lemmatize(word)\n",
    "        return new_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2bde60ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe\n",
    "path = 'C:\\\\Users\\\\Karthiek Duggirala\\\\Downloads\\\\my_dataframe.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7983f8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize preprocessor\n",
    "preprocessor = Preprocessor(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b9182dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "preprocessed_df = preprocessor.preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0325ce83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64543, 2)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "09449e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64527, 2)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f26f309e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lyrics</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>summer high school when we first met we would ...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yeah yeah yeah i can feel phoenix inside me i ...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>told them your dream they started i guess you ...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if i lost it today would you stay could my lov...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nice leg daisy duke make man go that is the wa...</td>\n",
       "      <td>pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              lyrics genre\n",
       "0  summer high school when we first met we would ...   pop\n",
       "1  yeah yeah yeah i can feel phoenix inside me i ...   pop\n",
       "2  told them your dream they started i guess you ...   pop\n",
       "3  if i lost it today would you stay could my lov...   pop\n",
       "4  nice leg daisy duke make man go that is the wa...   pop"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "af3841b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df.to_csv('C:\\\\Users\\\\Karthiek Duggirala\\\\Downloads\\\\preprocessed_data.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3865758a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63b2be1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
